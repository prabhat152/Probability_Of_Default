{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create python notebook pd.ipynb that include\n",
    "- A statistical model (Logistic Regression) to calculate the probability of default for retail mortgage customers.\n",
    "- use model parameters relevant to Dutch market. Also include two ESG related model parameters\n",
    "- A function to generate synthetic data for running the model.\n",
    "- add explicit linters to support beginner python developer\n",
    "- generate multiple relevant visualizations with explicit description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve\n",
    "import warnings\n",
    "\n",
    "# Explicitly define linting for beginner-friendly Python development\n",
    "# pylint: disable=invalid-name, too-few-public-methods, missing-function-docstring\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_synthetic_data(n_samples=1000, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Mortgage-relevant factors\n",
    "    loan_to_value = np.random.uniform(50, 100, n_samples)  # Loan-to-value ratio (50%-100%)\n",
    "    income = np.random.normal(50000, 15000, n_samples)  # Annual income in EUR\n",
    "    credit_score = np.random.randint(300, 850, n_samples)  # Credit score range\n",
    "    interest_rate = np.random.uniform(1.5, 6.0, n_samples)  # Interest rate in %\n",
    "    debt_to_income = np.random.uniform(20, 50, n_samples)  # Debt-to-income ratio in %\n",
    "    \n",
    "    # ESG factors\n",
    "    energy_efficiency = np.random.randint(1, 10, n_samples)  # Scale 1-10 (higher = better)\n",
    "    sustainability_loan = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])  # Sustainability loan flag\n",
    "    \n",
    "    # Probability of default (binary outcome: 1 = default, 0 = no default)\n",
    "    default_probability = (\n",
    "        0.3 * (loan_to_value / 100) +\n",
    "        -0.2 * (income / 100000) +\n",
    "        -0.25 * (credit_score / 850) +\n",
    "        0.2 * (interest_rate / 5) +\n",
    "        0.25 * (debt_to_income / 50) +\n",
    "        -0.15 * (energy_efficiency / 10) +\n",
    "        -0.1 * sustainability_loan +\n",
    "        np.random.normal(0, 0.1, n_samples)\n",
    "    )\n",
    "    default = (default_probability > np.median(default_probability)).astype(int)\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'Loan-to-Value': loan_to_value,\n",
    "        'Income': income,\n",
    "        'Credit Score': credit_score,\n",
    "        'Interest Rate': interest_rate,\n",
    "        'Debt-to-Income': debt_to_income,\n",
    "        'Energy Efficiency': energy_efficiency,\n",
    "        'Sustainability Loan': sustainability_loan,\n",
    "        'Default': default\n",
    "    })\n",
    "    return data\n",
    "\n",
    "# Generate dataset\n",
    "data = generate_synthetic_data()\n",
    "\n",
    "# Split data\n",
    "X = data.drop(columns=['Default'])\n",
    "y = data['Default']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'ROC AUC: {roc_auc:.2f}')\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance visualization\n",
    "feature_importance = pd.Series(model.coef_[0], index=X.columns).sort_values()\n",
    "plt.figure(figsize=(8, 6))\n",
    "feature_importance.plot(kind='barh', color='teal')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance in Logistic Regression')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
